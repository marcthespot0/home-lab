---
kind: Namespace
apiVersion: v1
metadata:
  name: ollama
---
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "-1"
spec:
  project: default
  source:
    repoURL: https://otwld.github.io/ollama-helm/
    targetRevision: "0.40.0"
    chart: ollama
    helm:
      values: |
        replicaCount: 1
        knative:
          enabled: false
          containerConcurrency: 1
          timeoutSeconds: 300
          responseStartTimeoutSeconds: 300
          idleTimeoutSeconds: 300
        image:
          repository: ollama/ollama
          pullPolicy: IfNotPresent
          tag: "latest"  # Specify version or "latest"
        imagePullSecrets: []
        nameOverride: ""
        fullnameOverride: ""
        ollama:
          persistentVolume:
            enabled: true
            existingClaim: "ollama-pvc"
            subPath: "/ollama"
          models:
            - llama3
          insecure: false
          volumeMounts:
            - name: ollama-volume
            mountPath: /ollama
          volumes:
            - name: ollama-volume
              persistentVolumeClaim:
                claimName: ollama-pvc
          runtimeClassName: "nvidia"
        service:
          type: LoadBalancer
          port: 11434
        nodeSelector:
          kubernetes.io/hostname: talos-lab-02
  destination:
    server: https://kubernetes.default.svc
    namespace: ollama
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
template:
  spec:
    containers:
    - name: ollama
      volumeMounts:
      - name: ollama-pvc
        mountPath: /ollama/models
    volumes:
    - name: ollama-pvc
      persistentVolumeClaim:
        claimName: ollama-pvc
---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: ollama-pvc
  namespace: ollama
  labels:
    app.kubernetes.io/name: ollama
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 100G

        
